# ODD: Data Transformations and Tukey's Ladder of Powers

```{r include = FALSE}
source("common.R")
ds4p_urls <- read.csv("./admin/csv/ds4p_urls.csv")
```

This optional deep dive covers data transformations, with a special focus on Tukey's Ladder of Powers, an invaluable tool for reshaping data distributions and relationships between variables. Our journey through this topic is inspired by @fox2016applied (ch. 4, pp. 28 - 80)

## Transforming Data: Tukey's Ladder of Powers


John Tukey introduced a methodological toolkit, likened to a set of drill bits of varying sizes, for modifying the shapes of distributions and relationships between variables. This section delves into these transformations, particularly focusing on the mathematical formulations that underpin this approach.

<!-- http://blackwell.math.yorku.ca/math4939/lectures/transforming_data_tukeys_ladder_of_powers.R -->

### Dataset Preparation and Visualization

We'll be using data from @fox2016applied. You may need to download the data manually and save it in the "data" directory within your current working directory. The dataset is available [here](http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-3E/datasets/UnitedNations.txt). You can use this r code `download.file("http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-3E/datasets/UnitedNations.txt"), "data/UnitedNations.txt")` to download the data.

```{r, echo=FALSE}
# Manual dataset preparation steps:
# 1. Download 'UnitedNations.txt' from the specified URL.
# 2. Save it in the "data" directory within your current working directory.
# URL for dataset download (uncomment and use as needed):
# fox_data <- "http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-3E/datasets/"
# download.file(paste0(fox_data, "UnitedNations.txt"), "data/UnitedNations.txt")
#
#if (!require("spida2")) devtools::install_github("smasongarrison/spida2",ref="patch-1")
# devtools::install_github("gmonette/spida2")
```
```{r,message=FALSE}
#if (!require("p3d")) install.packages("p3d", repos = "http://R-Forge.R-project.org")
library(p3d)
library(car)
library(latticeExtra)
library(gridExtra)
# read data
un <- read.table("data/UnitedNations.txt", header = TRUE)%>%
  mutate(country = rownames(.)) # Assigning country names
```

Let's visualize an attempt to make our regression behave. Below are the original and log-transformed relationships with ggplot2. You've likely used a log-transformation before, but we'll be exploring the more general family of transformations.

```{r,warning=FALSE,echo=FALSE , fig.width=6}


# First plot
p1 <- ggplot(un, aes(x = GDPperCapita, y = infantMortality)) +
  geom_point(color = "steelblue") +
  labs(title = "Infant Mortality",
       subtitle ="vs. GDP per Capita",
       x = "GDP per Capita", y = "Infant Mortality") +
  geom_smooth(method = "lm",
            color = "red", se = FALSE) +
  theme_bw() + coord_cartesian(ylim=c(0, 250) )

# Second plot
p2 <- ggplot(un, aes(x = log(GDPperCapita), y = log(infantMortality))) +
  geom_point(color = "steelblue") +
  labs(title = "Log-Transformed Infant Mortality",
       subtitle ="vs. GDP per Capita",
       x = "Log(GDP per Capita)", y = "Log(Infant Mortality)") +
  theme_bw()  + geom_smooth(method = "lm",
            color = "red", se = FALSE) +
  theme_bw() + coord_cartesian(ylim=c(0, log(250)) )

# Arrange the plots side by side
grid.arrange(p1, p2, ncol = 2)

```

It's clear that the log-transformation has straightened out the data, allowing us to fit a more useful regression line. However, we're not limited to just a log transformation. We can use an entire family of transformations to modify our data. This family of transformations is called Tukey's Ladder of Powers.

John Tukey suggested this simple toolkit, like a set drill bits of varying sizes, to modify the shape of distributions  and the shape of relationships between variables. 
The basic idea stems from the fact that functions of the form $y' = y^p, \quad y > 0$ have a graph that is concave up if $p >1$, and concave down if $0<p<1$ (or $p < 0$).  


```{r, caption = "Tukey's Ladder of Powers", echo=FALSE, fig.width=3}
# Create a data frame for plotting
x_vals <- seq(-2, 2, by = 0.1)
df <- expand.grid(x = x_vals, type = c("Concave Up", "Concave Down"))
df$y <- with(df, ifelse(type == "Concave Up", x^2, -x^2+4))

# Plot
ggplot(df, aes(x = x, y = y, col = type)) +
  geom_line() +
  labs(title = "Illustration of Concave Up and Down",
       x = "x", y = "y") +
  theme_minimal() +
  scale_color_manual(values = c("Concave Up" = "blue", "Concave Down" = "red")) +
  facet_wrap(~type, scales = "free_y") +theme_bw() +
  theme(legend.position = "none")
```

Concave Up ($y= x^2$): This plot shows a parabolic curve opening upwards, illustrating the concept of a concave up graph where the slope of the tangent line increases as $x$ increases.

Concave Down ($y= -x^2$): Conversely, this plot shows a parabolic curve opening downwards, illustrating a concave down graph where the slope of the tangent line decreases as $x$ increases.


We can use this information to modify the shape of a distribution or the shape of a relationship between variables by using a power transformation ( $p$) on our data. This family of transformations is called Tukey's Ladder of Powers.

Notably, $p < 0$, $y' = - y^p, \quad y > 0$, is also concave down.

Now, this graph leaves out $p=0$ but we will see shortly that $y' = \ln y$ is the sensible transformation that corresponds to $p = 0$.

Now, we standardize the family of power transformations so that they have the value 0 when $y = 1$ and so their derivative is equal to 1 when $y=1$.

For $p \ne 0$, this yields $$y' = \frac{y^p - 1}{p}$$

Note that, by l’Hôpital’s rule:

$$\lim_{p \to 0} \frac{y^p - 1}{p}= \lim_{p \to 0}\, e^{\, p \ln y} \ln  y = \ln  y$$

We define a function that produces this transformation. The easy way to define it is:

```{r}
pow <- function(y, p) {
  if (p == 0) {
    log(y)
  } else {
    (y^p - 1) / p
  }
}

# Testing the transformation with a sequence of x values
x <- seq(-1, 3, by = .5)

# Applying the transformation for different powers of p
x_transformed <- tibble(
  x = x,
  `p=2` = pow(x, 2),
  `p=0` = pow(x, 0),
  `p=-1` = pow(x, -1)
)


# Visualizing the transformed data
x_transformed_long <- pivot_longer(x_transformed, cols = starts_with("p"), names_to = "Power", values_to = "Transformed")

ggplot(x_transformed_long, aes(x = x, y = Transformed, color = Power)) +
  geom_line() +
  labs(title = "Visualization of Power Transformations", x = "Original x", y = "Transformed x")


# test:
x <- seq(-1, 3,by =  .5)
x # note that these transformations are really intended for y > 0
pow(x, 2)
pow(x, 0) %>%
  name(x)
pow(x, -1) %>%
  name(x) %>%
  cbind()

plot(exp) # easy plotting of a function
plot(function(x) pow(x, p = 2)) # anonymous function or 'lambda'
plot(function(x) pow(x, p = .5), xlim = c(0, 3))
```

But this approach has the disadvantage that it works correctly only for a single value of $p$ because the statement `if(p == 0)` only tests the first element of `p`.

## Vectorizing a function

Most operators in R are __vectorized__ so they work element-wise when their arguments are vectors. When the arguments have incompatible lengths, the shorter argument is __recycled__ to have the same length as the longer one. That is why the following produces sensible results:

```{r}
z <- c(3, 5, 9)
z + c(1, 1, 1)
z + 1 # 1 is recycled so the result is equivalent to the previous line
z + c(1, 2, 3)
z + c(1, 2) # recycles but gives a warning
z + z
z^2
z^z
```

We can use `ifelse` which works on a vector instead of a single value.

```{r}
pow <- function(y, p) {
  p <- rep(p, length.out = length(y))
  y <- rep(y, length.out = length(p))
  ifelse(p == 0, log(y), (y^p - 1) / p)
}

# To apply the function over vectors of y and p, ensuring vectorized operations:
vectorized_pow <- function(y, p) {
  map2(y, p, pow)
}
# test:
pow(-1:4, c(2, 0, -1, 1, 3))
pow(-1:4, 2)
```

With a bit more work, we can avoid unnecessary evaluations:

```{r}
pow <- function(y, p) {
  p <- rep(p, length.out = length(y))
  y <- rep(y, length.out = length(p))
  y[p == 0] <- log(y[p == 0])
  y[p != 0] <- (y[p != 0]^p[p != 0] - 1) / p[p != 0]
  y
}

# Test:

pow(1:10, 0) == log(1:10)
pow(1:10, -1)
pow(1:10, .5)
pow(1:10, -1:8)
```

Let's plot this transformation for a range of values of $p$. The value of `expand.grid` is a data frame whose rows consist of the Cartesian product (i.e. all possible combinations) of its arguments.

```{r}
expand.grid(a = c("A", "B"), x = 1:3)


dd <- expand.grid(y = seq(.01, 3, .01), p = c(-2, -1, -.5, 0, .5, 1, 2, 3))
dim(dd)
head(dd)
some(dd) # 10 rows at random


dd$yval <- with(dd, pow(y, p))
xyplot(yval ~ y | factor(p), dd, type = "l")
xyplot(yval ~ y | factor(p), dd, type = "l", ylim = c(-2, max(dd$yval)))
xyplot(yval ~ y, dd, groups = p, type = "l", ylim = c(-2, max(dd$yval)))
xyplot(yval ~ y, dd,
  groups = p,
  type = "l",
  xlim = c(0, 3),
  ylim = c(-2, max(dd$yval))
)
gd(8, lwd = 2) # number of colours needed
xyplot(yval ~ y, dd,
  groups = p,
  type = "l",
  xlim = c(0, 3),
  ylim = c(-2, max(dd$yval))
)
xyplot(yval ~ y, dd,
  groups = p,
  type = "l",
  auto.key = list(space = "right", lines = T, points = F),
  xlim = c(0, 3),
  ylim = c(-2, max(dd$yval))
)
```

It's much better to have the legend in the same order as the lines in the graph. We can turn `p` into a factor and reverse its order.

```{r}
dd$po <- factor(dd$p)
dd$po <- reorder(dd$po, -dd$p)
xyplot(yval ~ y, dd,
  groups = po,
  type = "l",
  auto.key = list(space = "right", lines = T, points = F, title = "power"),
  xlim = c(0, 3),
  ylim = c(-2, max(dd$yval))
)
```

From quantile plots:

Uniform quantiles...

```{r}
xqplot(un)
```

Normal quantiles

```{r}
xqplot(un, ptype = "normal")
```

We see that none of the numeric variables have normal distributions.  

- 'age' is somewhat platykurtic compared with a normal
- 'compositeHourlyWages' has both a categorical (0) and  a continuous component
- 'education' is also platykurtic
- 'working' is dichotomous
- 'familyIncome' is skewed to the right

Note that the fact that $x$ or $y$ variables are not normal does not mean that the conditional distribution of $y$ given $x$ is not normal.  

Let's explore wages of working women as a function of education.

```{r}
library(latticeExtra)
un %>%
  xyplot(infantMortality ~ GDPperCapita, .) +
  layer(panel.loess(..., lwd = 2))


# Scatterplot showing curvature in relationship

trellis.focus()
panel.identify(labels = rownames(un))
trellis.unfocus()

un %>%
  xyplot(log(infantMortality) ~ GDPperCapita | region, .) +
  layer(panel.loess(..., lwd = 2))

un %>% subset(country %in% c("United.States", "Canada"))
```

between wage and education, and heteroskedasticity in wage as a function of education.

```{r}
# library(p3d)

# slid %>%
#  xyplot(sqrt(wage) ~ education, .) +
#  layer(panel.loess(...))

# Init3d()
# Plot3d(log(infantMortality) ~ GDPperCapita + lifeFemale | region, un)
# Id3d()
# Id3d('United.States')
# Id3d('Canada')
# rownames(un)
# names(un)
```

## Box Cox Transformation

```{r, echo=FALSE}
# not mine, but still good
"https://www.youtube.com/watch?v=vGOpEpjz2Ks" %>%
  embed_url() %>%
  use_align("center")
```

This video was made by [math et al](https://www.youtube.com/channel/UCYNVcihAKkRW-bhzIrguvVw). I like their channel and found this video to be a good one.

### Additional Resources

- Salvatore S. Mangiafico's Summary and Analysis of Extension Program Evaluation in R, [rcompanion.org/handbook/](http://rcompanion.org/handbook/). [Pdf version]( http://rcompanion.org/documents/RHandbookProgramEvaluation.pdf)

- <http://www.unige.ch/ses/sococ/cl//stat/eda/ladder.html>
- <https://www.statisticshowto.com/tukey-ladder-of-powers/>
- <http://blackwell.math.yorku.ca/math4939/lectures/transforming_data_tukeys_ladder_of_powers.html>
- <https://thomaselove.github.io/431-notes/re-expression-tukeys-ladder-box-cox-plot.html>

```{r links, child="admin/md/courselinks.md"}
```
