[["index.html", "Data Science for Psychologists A Modernized Exploratory and Graphical Data Analysis with R Welcome to PSY 703", " Data Science for Psychologists A Modernized Exploratory and Graphical Data Analysis with R S. Mason Garrison 2021-01-11 Welcome to PSY 703 Welcome to class! This website is designed to accompany Mason Garrisons Data Science for Psychologists (DS4P). DS4P is a graduate-level quantitative methods course at Wake Forest University. This website hosts the lab notes. All the embedded lecture videos can be found on a youtube playlist. You can find the current version of the course syllabus here, along with all of the other syllabi for my classes. "],["overview.html", "Overview", " Overview This module is designed to orient you to the class. Please watch the videos and work your way through the notes. Although the videos are embedded into the course, you can find the video playlist here. "],["course-introduction.html", "Course Introduction Big Ideas", " Course Introduction Data Science for Psychologists (DS4P) introduces on the principles of data science, including: data wrangling, modeling, visualization, and communication. In this class, we link those principles to psychological methods and open science practices by emphasizing exploratory analyses and description, rather than confirmatory analyses and prediction. Through the semester we will work our way thru Wickham and Grolemunds R for Data Science text and develop proficiency with tidyverse. This class emphasizes replication and reproducibility. DS4P is a practical skilled-based class and should be useful to students aiming for academia as well as those interested in industry. Applications of these methods can be applied to a full range of psychological areas, including perception (e.g, eye-tracking data), neuroscience (e.g., visualizing neural networks), and individual differences (e.g., valence analysis). Big Ideas This class covers the following broad five areas: Reproducibility; Replication; Robust Methods; Resplendent Visualizations; and R Programming. "],["materials.html", "Materials Hardware Required Texts Software Course Modality Knowledge is Power Attribution Colophon License", " Materials Hardware This class is requires that you have a laptop that can run R. Required Texts The text is intended to supplement the videos, lecture notes, and in-class tutorials. You need to consume all four in order to be successful in this class. R for Data Science text (???) Software R R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows, and MacOS. R Studio RStudio is a free integrated development environment (IDE), a powerful user interface for R. Git Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files  called a repository  in a structured way. Think of it like the Track Changes features from Microsoft Word. Github Github is a free IDE and hosting service for Git. As a Wake Forest student, you should be able to access the GitHub Student Developer Pack for free. It includes a free PRO upgrade for your github account Course Modality This class is a blended class. The online portions are asynchronous. Ive created a video highlighting how to be a successful asynchronous learner. Much of this information comes from Northeastern Universitys Tips for Taking Online Classes Knowledge is Power This brief video is covers the icebreaker I do in all of my classes. I encourage you to watch it as in it I discuss stereotype threats and stats anxiety. Attribution This class leans heavily on other peoples materials and ideas. I have done my best to document the origin of the materials and ideas. They include: Jenny Bryans (jennybryan.org) STAT 545; Joe Rodgerss PSY 8751 Exploratory and Graphical Data Analysis Course Julia Fukuyamas EXPLORATORY DATA ANALYSIS Mine Çetinkaya-Rundels Data Science in a Box. You can see specific changes by examining the edit history on the git repo Colophon This book was written in bookdown inside RStudio. The website r-computing-lab.github.io/DataScience4Psych is hosted with github, The complete source is available from GitHub. The Psych 703 logo was designed by me and the book style was designed by Desirée De Leon. This version of the book was built with: #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.0.3 (2020-10-10) #&gt; os Windows 10 x64 #&gt; system x86_64, mingw32 #&gt; ui RTerm #&gt; language (EN) #&gt; collate English_United States.1252 #&gt; ctype English_United States.1252 #&gt; tz America/New_York #&gt; date 2021-01-11 Along with these packages: License This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. This is a human-readable summary of (and not a substitute for) the license. Please see https://creativecommons.org/licenses/by-sa/4.0/legalcode for the full legal text. You are free to: Sharecopy and redistribute the material in any medium or format Remixremix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: AttributionYou must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlikeIf you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictionsYou may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material. "],["lab-01-hello-r.html", "Lab 1 Lab 01 - Hello R! 1.1 Getting started 1.2 Warm up 1.3 The data 1.4 Exercises", " Lab 1 Lab 01 - Hello R! R is the name of the programming language itself and RStudio is a convenient interface. The main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions. git is a version control system (like &quot;Track Changes&quot; features from Microsoft Word on steroids) and GitHub is the home for your Git-based projects on the internet (like DropBox but much, much better). An additional goal is to introduce you to git and GitHub, which is the collaboration and version control system that we will be using throughout the course. As the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands. And to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel. Next week youll learn about collaborating on GitHub and produce a single lab report for your team. 1.1 Getting started Each of your assignments will begin with the following steps. You saw these once in class yesterday, theyre outlined in detail here again. Going forward each lab will start with a Getting started section but details will be a bit more sparse than this. You can always refer back to this lab for a detailed list of the steps involved for getting started with an assignment. The following screencast also walks you through these steps: Click on the assignment link that you should have received in your email to create your GitHub repository (which well refer to as repo going forward) for the assignment. This repo contains a template you can build on to complete your assignment. On GitHub, click on the green Clone or download button, select Use HTTPS (this might already be selected by default, and if it is, youll see the text Clone with HTTPS as in the image below). Click on the clipboard icon to copy the repo URL. Go to RStudio Cloud and into the course workspace. Create a New Project from Git Repo. You will need to click on the down arrow next to the New Project button to see this option. Copy and paste the URL of your assignment repo into the dialog box: Hit OK, and youre good to go! 1.1.1 Packages In this lab we will work with two packages: datasauRus which contains the dataset, and tidyverse which is a collection of packages for doing data analysis in a tidy way. Install these packages by running the following in the console. install.packages(&quot;tidyverse&quot;) install.packages(&quot;datasauRus&quot;) Now that the necessary packages are installed, you should be able to Knit your document and see the results. If youd like to run your code in the Console as well youll also need to load the packages there. To do so, run the following in the console. library(tidyverse) library(datasauRus) Note that the packages are also loaded with the same commands in your R Markdown document. 1.1.2 Housekeeping Your email address is the address tied to your GitHub account and your name should be first and last name. Before we can get started we need to take care of some required housekeeping. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your email address and your name. To do so, run the following: usethis::use_git_config(user.name = &quot;your name&quot;, user.email = &quot;your email&quot;) For example, for me this looks like: usethis::use_git_config(user.name = &quot;Mine Cetinkaya-Rundel&quot;, user.email = &quot;cetinkaya.mine@gmail.com&quot;) 1.2 Warm up Before we introduce the data, lets warm up with some simple exercises. The following video is an overview of some of these warm-up exercises. 1.2.1 Project name Currently your project is called Untitled Project. Update the name of your project to be Lab 01 - Hello R. The top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for &quot;YAML Ain&#39;t Markup Language&quot;. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document. 1.2.2 YAML Open the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document. 1.2.3 Committing changes Then go to the Git pane in your RStudio. If you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state that includes your changes. If youre happy with these changes, write Update author name in the Commit message box and hit Commit. You dont have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions. 1.2.4 Pushing changes Now that you have made an update and committed this change, its time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only). In order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me We will teach you how to save your password so you dont have to enter it every time. But for this one assignment youll have to manually enter each time you push in order to gain some experience with it. 1.2.5 Thought exercise For which of the above steps (changing project name, making updates to the document, committing, and pushing changes) do you need to have an internet connection? Discuss with your classmates. 1.3 The data If it&#39;s confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you&#39;re not alone! Have you heard of a [baker&#39;s dozen](https://en.wikipedia.org/wiki/Dozen#Baker&#39;s_dozen)? The data frame we will be working with today is called datasaurus_dozen and its in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualisation is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable. To find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console. 1.4 Exercises Based on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report. When youre done, commit your changes with the commit message Added answer for Ex 1, and push. Lets take a look at what these datasets are. To do so we can make a frequency table of the dataset variable: datasaurus_dozen %&gt;% count(dataset) %&gt;% print(13) ## # A tibble: 13 x 2 ## dataset n ## &lt;chr&gt; &lt;int&gt; ## 1 away 142 ## 2 bullseye 142 ## 3 circle 142 ## 4 dino 142 ## 5 dots 142 ## 6 h_lines 142 ## 7 high_lines 142 ## 8 slant_down 142 ## 9 slant_up 142 ## 10 star 142 ## 11 v_lines 142 ## 12 wide_lines 142 ## 13 x_shape 142 Matejka, Justin, and George Fitzmaurice. &quot;Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing.&quot; Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2017. The original Datasaurus (dino) was created by Alberto Cairo in this great blog post. The other Dozen were generated using simulated annealing and the process is described in the paper Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of datasets that have the same summary statistics as the Datasaurus but have very different distributions. Plot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset. Below is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your Rmd document and successfully knit it and view the results. Start with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data. dino_data &lt;- datasaurus_dozen %&gt;% filter(dataset == &quot;dino&quot;) There is a lot going on here, so lets slow down and unpack it a bit. First, the pipe operator: %&gt;%, takes what comes before it and sends it as the first argument to what comes after it. So here, were saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\". Second, the assignment operator: &lt;-, assigns the name dino_data to the filtered data frame. Next, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data youre visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point. ggplot(data = dino_data, mapping = aes(x = x, y = y)) + geom_point() If this seems like a lot, it is. And you will learn about the philosophy of building data visualizations in layer in detail next week. For now, follow along with the code that is provided. For the second part of these exercises, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as \\(r\\) in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesnt make sense since the relationship between x and y is definitely not linear  its dinosaurial! But, for illustrative purposes, lets calculate the correlation coefficient between x and y. Start with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`. dino_data %&gt;% summarize(r = cor(x, y)) ## # A tibble: 1 x 1 ## r ## &lt;dbl&gt; ## 1 -0.0645 This is a good place to pause, commit changes with the commit message Added answer for Ex 2, and push. Plot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino? This is another good place to pause, commit changes with the commit message Added answer for Ex 3, and push. Plot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino? You should pause again, commit changes with the commit message Added answer for Ex 4, and push. Facet by the dataset variable, placing the plots in a 3 column grid, and don&#39;t add a legend. Finally, lets plot all datasets at once. In order to do this we will make use of facetting. ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+ geom_point()+ facet_wrap(~ dataset, ncol = 3) + theme(legend.position = &quot;none&quot;) And we can use the group_by function to generate all the summary correlation coefficients. datasaurus_dozen %&gt;% group_by(dataset) %&gt;% summarize(r = cor(x, y)) %&gt;% print(13) Youre done with the data analysis exercises, but wed like you to do two more things: Resize your figures: Click on the gear icon in on top of the R Markdown document, and select Output Options in the dropdown menu. In the pop up dialogue box go to the Figures tab and change the height and width of the figures, and hit OK when done. Then, knit your document and see how you like the new sizes. Change and knit again and again until youre happy with the figure sizes. Note that these values get saved in the YAML. You can also use different figure sizes for differen figures. To do so click on the gear icon within the chunk where you want to make a change. Changing the figure sizes added new options to these chunks: fig.width and fig.height. You can change them by defining different values directly in your R Markdown document as well. Change the look of your report: Once again click on the gear icon in on top of the R Markdown document, and select Output Options in the dropdown menu. In the General tab of the pop up dialogue box try out different Syntax highlighting and theme options. Hit OK and knit your document to see how it looks. Play around with these until youre happy with the look. Not sure how to use emojis on your computer? Maybe a teammate can help? Or you can ask your TA as well! Yay, youre done! Commit all remaining changes, use the commit message Done with Lab 1! , and push. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo. "],["lab-02-global-plastic-waste.html", "Lab 2 Lab 02 - Global plastic waste 2.1 Getting started 2.2 The data 2.3 Exercises 2.4 Analysis", " Lab 2 Lab 02 - Global plastic waste **A note on expectations: ** For each exercise and on your own question you answer include any relevant output (tables, summary statistics, plots) in your answer. Doing this is easy! Just place any relevant R code in a code chunk, and hit Knit HTML. Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010. Additionally, National Geographic recently ran a data visualization communication contest on plastic waste as seen here. Learning goals for this lab are: Visualize numerical and categorical data. Recreate visualizations. Get more practice using with Git and GitHub. 2.1 Getting started **IMPORTANT:** If there is no GitHub repo created for you for this assignment, it means I didn&#39;t have your GitHub username as of when I assigned the homework. Please let me know your GitHub username asap, and I can create your repo. Go to the course GitHub organization and locate your Lab 02 repo, which should be named lab-02-plastic-waste-YOUR_GITHUB_USERNAME. Grab the URL of the repo, and clone it in RStudio. Refer to Lab 01 if you would like to see step-by-step instructions for cloning a repo into an RStudio project. First, open the R Markdown document lab-02-plastic-waste.Rmd and Knit it. Make sure it compiles without errors. The output will be in the file markdown .md file with the same name. 2.1.1 Packages Well use the tidyverse package for this analysis. Run the following code in the Console to load this package. library(tidyverse) 2.1.2 Housekeeping Your email address is the address tied to your GitHub account and your name should be first and last name. Before we can get started we need to take care of some required housekeeping. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your email address and your name. To do so, run the following: usethis::use_git_config(user.name = &quot;your name&quot;, user.email = &quot;your email&quot;) For example, for me this looks like: usethis::use_git_config(user.name = &quot;Mine Cetinkaya-Rundel&quot;, user.email = &quot;cetinkaya.mine@gmail.com&quot;) 2.2 The data The dataset for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following. plastic_waste &lt;- read_csv(&quot;data/plastic-waste.csv&quot;) The variable descriptions are as follows: code: 3 Letter country code entity: Country name continent: Continent name year: Year gdp_per_cap: GDP per capita constant 2011 international $, rate plastic_waste_per_cap: Amount of plastic waste per capita in kg/day mismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day mismanaged_plastic_waste: Tonnes of mismanaged plastic waste coastal_pop: Number of individuals living on/near coast total_pop: Total population according to Gapminder 2.3 Exercises Lets start by taking a look at the distribution of plastic waste per capita in 2010. ggplot(data = plastic_waste, aes(x = plastic_waste_per_cap)) + geom_histogram(binwidth = 0.2) ## Warning: Removed 51 rows containing non-finite values (stat_bin). One country stands out as an unusual observation at the top of the distribution. One way of identifying this country is to filter the data for countries where plastic waste per capita is greater than 3.5 kg/person. plastic_waste %&gt;% filter(plastic_waste_per_cap &gt; 3.5) ## # A tibble: 1 x 10 ## code entity continent year gdp_per_cap plastic_waste_p~ mismanaged_plas~ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 TTO Trini~ North Am~ 2010 31261. 3.6 0.19 ## # ... with 3 more variables: mismanaged_plastic_waste &lt;dbl&gt;, coastal_pop &lt;dbl&gt;, ## # total_pop &lt;dbl&gt; Did you expect this result? You might consider doing some research on Trinidad and Tobago to see why plastic waste per capita is so high there, or whether this is a data error. Plot, using histograms, the distribution of plastic waste per capita faceted by continent. What can you say about how the continents compare to each other in terms of their plastic waste per capita? From this point onwards the plots / output of the code won&#39;t be printed in the lab, but you can run the code and view the results yourself. Another way of visualizing numerical data is using density plots. ggplot(data = plastic_waste, aes(x = plastic_waste_per_cap)) + geom_density() And compare distributions across continents by coloring density curves by continent. ggplot(data = plastic_waste, mapping = aes(x = plastic_waste_per_cap, color = continent)) + geom_density() The resulting plot may be a little difficult to read, so lets also fill the curves in with colors as well. ggplot(data = plastic_waste, mapping = aes(x = plastic_waste_per_cap, color = continent, fill = continent)) + geom_density() The overlapping colors make it difficult to tell whats happening with the distributions in continents plotted first, and hence coverred by continents plotted over them. We can change the transparency level of the fill color to help with this. The alpha argument takes values between 0 and 1: 0 is completely transparent and 1 is completely opaque. There is no way to tell what value will work best, so you just need to try a few. ggplot(data = plastic_waste, mapping = aes(x = plastic_waste_per_cap, color = continent, fill = continent)) + geom_density(alpha = 0.7) This still doesnt look great Recreate the density plots above using a different (lower) alpha level that works better for displaying the density curves for all continents. Describe why we defined the color and fill of the curves by mapping aesthetics of the plot but we defined the alpha level as a characteristic of the plotting geom.   Now is a good time to commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards. And yet another way to visualize this relationship is using side-by-side box plots. ggplot(data = plastic_waste, mapping = aes(x = continent, y = plastic_waste_per_cap)) + geom_boxplot() Learn something new: violin plots! Read about them at http://ggplot2.tidyverse.org/reference/geom_violin.html, and convert your side-by-side box plots from the previous task to violin plots. What do the violin plots reveal that box plots do not? What features are apparent in the box plots but not in the violin plots? Remember that we use `geom_point()` to make scatterplots. Visualize the relationship between plastic waste per capita and mismanaged plastic waste per capita using a scatterplot. Describe the relationship. Color the points in the scatterplot by continent. Does there seem to be any clear distinctions between continents with respect to how plastic waste per capita and mismanaged plastic waste per capita are associated? Visualize the relationship between plastic waste per capita and total population as well as plastic waste per capita and coastal population. Do either of these pairs of variables appear to be more strongly linearly associated?   Now is another good time to commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards. Hint: The x-axis is a calculated variable. One country with plastic waste per capita over 3 kg/day has been filtered out. And the colors are from the viridis color palette. Take a look at the functions starting with `scale_color_viridis_*`. Recreate the following plot, and interpret what you see in context of the data.   Commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards. [sometext]offset=2900 # Pieces 2900-2909 We can construct these URLs in R by pasting together two pieces: (1) a common (`root`) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2900. Two new functions are helpful for accomplishing this: `paste0()` for pasting two pieces of text and `seq()` for generating a sequence of numbers. 7. Fill in the blanks to construct the list of URLs. ### Mapping Finally, we&#39;re ready to iterate over the list of URLs we constructed. We will do this by **map**ping the function we developed over the list of URLs. There are a series of mapping functions in R (which we&#39;ll learn about in more detail tomorrow), and they each take the following form: map([x], [function to apply to each element of x]) In our case `x` is the list of URLs we constructed and the function to apply to each element of `x` is the function we developed earlier, `scrape_page`. And as a result we want a data frame, so we use `map_dfr` function: ```r map_dfr(urls, scrape_page) Fill in the blanks to scrape all pages, and to create a new data frame called uoe_art. 2.3.1 Write out data Finally write out the data frame you constructed into the data folder so that you can use it in the analysis section. 2.4 Analysis Work in lab-06-uoe-art.Rmd for the rest of the lab. Now that we have a tidy dataset that we can analyze, lets do that! Well start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses. Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses. This should be interesting to clean up! First thing well try is to separate the title column into two: one for the actual title and the other for the date if it exists. In human speak, we need to separate the title column at the first occurence of ( and put the contents on one side of the ( into a column called title and the contents on the other side into a column called date Luckily, theres a function that does just this: separate()! And once we have completed separating the single title column into title and date, we need to do further cleanup in the date column to get rid of extraneous )s with str_remove(), capture year information, and save the data as a numeric variable. **Hint:** Remember escaping special characters from yesterday&#39;s lecture? You&#39;ll need to use that trick again. Fill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and thats OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture year where its convenient to do so. Print out a summary of the dataframe using the skim() function. How many pieces have artist info missing? How many have year info missing? Make a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary? **Hint:** You&#39;ll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction. Find which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didnt capture the correct year information? Correct the error in the data frame and visualize the data again. Who is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them? **Hint:** You&#39;ll want to use a combination of `filter()` and `str_detect()`. You will want to read the help for `str_detect()` at a minimum, and consider how you might capture titles where the word appears as &quot;child&quot; and &quot;Child&quot;. Final question! How many art pieces have the word child in their title? See if you can figure it out, and ask for help if not. "],["lab-09-professor-attractiveness-and-course-evaluations-pt-1.html", "Lab 3 Lab 09 - Professor attractiveness and course evaluations, Pt 1 3.1 Modelling with a single predictor 3.2 Getting started 3.3 Warm up 3.4 The data 3.5 Exercises", " Lab 3 Lab 09 - Professor attractiveness and course evaluations, Pt 1 3.1 Modelling with a single predictor 3.2 Getting started Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.) For this assignment you will analyze the data from this study in order to learn what goes into a positive professor evaluation. The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors. 3.2.1 Packages In this lab we will work with the tidyverse, openintro, and broom packages. library(tidyverse) library(broom) library(openintro) 3.2.2 Housekeeping 3.2.2.1 Git configuration / password caching Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time. 3.2.2.2 Project name Update the name of your project to match the labs title. 3.3 Warm up Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer. Before we introduce the data, lets warm up with some simple exercises. 3.3.1 YAML Open the R Markdown (Rmd) file in your project, change the author name to your team name, and knit the document. 3.3.2 Commiting and pushing changes Go to the Git pane in your RStudio. View the Diff and confirm that you are happy with the changes. Add a commit message like Update team name in the Commit message box and hit Commit. Click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. 3.3.3 Pulling changes Now, the remaining team members who have not been concurrently making these changes on their projects should click on the Pull button in their Git pane and observe that the changes are now reflected on their projects as well. 3.4 The data The dataset well be using is called evals from the openintro package. Take a peek at the codebook with ?evals. 3.5 Exercises 3.5.1 Part 1: Exploratory Data Analysis Visualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response. Visualize and describe the relationship between score and the new variable you created, bty_avg. **Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html. Replot the scatterplot from Exercise 3, but this time use geom_jitter()? What does jitter mean? What was misleading about the initial scatterplot? 3.5.2 Part 2: Linear regression with a numerical predictor Linear model is in the form $\\hat{y} = b_0 + b_1 x$. Lets see if the apparent trend in the plot is something more than natural variation. Fit a linear model called m_bty to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model. Replot your visualization from Exercise 3, and add the regression line to this plot in orange color. Turn off the shading for the uncertainty of the line. Interpret the slope of the linear model in context of the data. Interpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context. Determine the \\(R^2\\) of the model and interpret it in context of the data. 3.5.3 Part 3: Linear regression with a categorical predictor Fit a new linear model called m_gen to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data. What is the equation of the line corresponding to male professors? What is it for female professors? Fit a new linear model called m_rank to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Create a new variable called rank_relevel where \"tenure track\" is the baseline level. Fit a new linear model called m_rank_relevel to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 13. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model. Create another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\". Fit a new linear model called m_tenure_eligible to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in Exercise 15. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model. "],["lab-10-professor-attractiveness-and-course-evaluations-pt-2.html", "Lab 4 Lab 10 - Professor attractiveness and course evaluations, Pt. 2\" 4.1 Modelling with multiple predictors\" 4.2 Getting started 4.3 Warm up 4.4 The data 4.5 Exercises", " Lab 4 Lab 10 - Professor attractiveness and course evaluations, Pt. 2\" 4.1 Modelling with multiple predictors\" In this lab we revisit the professor evaluations data we modeled in the previous lab. In the last lab we modeled evaluation scores using a single predictor at a time. However this time we use multiple predictors to model evaluation scores. If you dont remember the data, review the previous labs introduction before continuing to the exercises. 4.2 Getting started 4.2.1 Packages In this lab we will work with the tidyverse, openintro, and broom packages. library(tidyverse) library(broom) library(openintro) 4.2.2 Housekeeping 4.2.2.1 Git configuration / password caching Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time. 4.2.2.2 Project name Update the name of your project to match the labs title. 4.3 Warm up Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer. Before we introduce the data, lets warm up with some simple exercises. 4.3.1 YAML Open the R Markdown (Rmd) file in your project, change the author name to your team name, and knit the document. 4.3.2 Commiting and pushing changes Go to the Git pane in your RStudio. View the Diff and confirm that you are happy with the changes. Add a commit message like Update team name in the Commit message box and hit Commit. Click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. 4.3.3 Pulling changes Now, the remaining team members who have not been concurrently making these changes on their projects should click on the Pull button in their Git pane and observe that the changes are now reflected on their projects as well. 4.4 The data The dataset well be using is called evals from the openintro package. Take a peek at the codebook with ?evals. 4.5 Exercises Load the data by including the appropriate code in your R Markdown file. 4.5.1 Part 1: Simple linear regression Fit a linear model (one you have fit before): m_bty, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\). 4.5.2 Part 2: Multiple linear regression Fit a linear model (one you have fit before): m_bty_gen, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\). Interpret the slope and intercept of m_bty_gen in context of the data. What percent of the variability in score is explained by the model m_bty_gen. What is the equation of the line corresponding to just male professors? For two professors who received the same beauty rating, which gender tends to have the higher course evaluation score? How does the relationship between beauty and evaluation score vary between male and female professors? How do the adjusted \\(R^2\\) values of m_bty_gen and m_bty compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beaty score of the professor. Compare the slopes of bty_avg under the two models (m_bty and m_bty_gen). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg? Create a new model called m_bty_rank with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data. 4.5.3 Part 3: The search for the best model Going forward, only consider the following variables as potential predictors: rank, ethnicity, gender, language, age, cls_perc_eval, cls_did_eval, cls_students, cls_level, cls_profs, cls_credits, bty_avg. Which variable, on its own, would you expect to be the worst predictor of evaluation scores? Why? Hint: Think about which variable would you expect to not have any association with the professors score. Check your suspicions from the previous exercise. Include the model output for that variable in your response. Suppose you wanted to fit a full model with the variables listed above. If you are already going to include cls_perc_eval and cls_students, which variable should you not include as an additional predictor? Why? Fit a full model with all predictors listed above (except for the one you decided to exclude) in the previous question. Using backward-selection with adjusted R-squared as the selection criterion, determine the best model. You do not need to show all steps in your answer, just the output for the final model. Also, write out the linear model for predicting score based on the final model you settle on. Interpret the slopes of one numerical and one categorical predictor based on your final model. Based on your final model, describe the characteristics of a professor and course at University of Texas at Austin that would be associated with a high evaluation score. Would you be comfortable generalizing your conclusions to apply to professors generally (at any university)? Why or why not? "],["lab-11-so-what-if-you-smoke-when-pregnant.html", "Lab 5 Lab 11 - So what if you smoke when pregnant?\" 5.1 Simulation based inference 5.2 Getting started 5.3 Housekeeping 5.4 Warm up 5.5 Set a seed! 5.6 The data 5.7 Exercises 5.8 Lab 12 - Work on projects", " Lab 5 Lab 11 - So what if you smoke when pregnant?\" 5.1 Simulation based inference In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of observations from this data set. 5.2 Getting started 5.2.1 Packages In this lab we will work with the tidyverse, infer, and openintro packages. We can install and load them with the following: library(tidyverse) library(infer) library(openintro) 5.3 Housekeeping 5.3.1 Git configuration / password caching Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time. 5.3.2 Project name Update the name of your project to match the labs title. 5.4 Warm up Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer. Before we introduce the data, lets warm up with some simple exercises. 5.4.1 YAML Open the R Markdown (Rmd) file in your project, change the author name to your team name, and knit the document. 5.4.2 Commiting and pushing changes Go to the Git pane in your RStudio. View the Diff and confirm that you are happy with the changes. Add a commit message like Update team name in the Commit message box and hit Commit. Click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. 5.4.3 Pulling changes Now, the remaining team members who have not been concurrently making these changes on their projects should click on the Pull button in their Git pane and observe that the changes are now reflected on their projects as well. 5.5 Set a seed! In this lab well be generating random samples. The last thing you want is those samples to change every time you knit your document. So, you should set a seed. Theres an R chunk in your R Markdown file set aside for this. Locate it and add a seed. Make sure all members in a team are using the same seed so that you dont get merge conflicts and your results match up for the narratives. 5.6 The data Load the ncbirths data from the openintro package: data(ncbirths) We have observations on 13 different variables, some categorical and some numerical. The meaning of each variable is as follows. variable description fage fathers age in years. mage mothers age in years. mature maturity status of mother. weeks length of pregnancy in weeks. premie whether the birth was classified as premature (premie) or full-term. visits number of hospital visits during pregnancy. marital whether mother is married or not married at birth. gained weight gained by mother during pregnancy in pounds. weight weight of the baby at birth in pounds. lowbirthweight whether baby was classified as low birthweight (low) or not (not low). gender gender of the baby, female or male. habit status of the mother as a nonsmoker or a smoker. whitemom whether mom is white or not white. 5.7 Exercises What are the cases in this data set? How many cases are there in our sample? The first step in the analysis of a new dataset is getting acquanted with the data. Make summaries of the variables in your dataset, determine which variables are categorical and which are numerical. For numerical variables, are there outliers? If you arent sure or want to take a closer look at the data, make a graph. 5.7.1 Baby weights Wen, Shi Wu, Michael S. Kramer, and Robert H. Usher. &quot;Comparison of birth weight distributions between Chinese and Caucasian infants.&quot; American Journal of Epidemiology 141.12 (1995): 1177-1187. A 1995 study suggestes that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds). In this dataset we only have information on mothers race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e. whitemom = \"white\". We want to evaluate whether the average weight of Caucasian babies has changed since 1995. Our null hypothesis should state there is nothing going on, i.e. no change since 1995: \\(H_0: \\mu = 7.43~pounds\\). Our alternative hypothesis should reflect the research question, i.e. some change since 1995. Since the research question doesnt state a direction for the change, we use a two sided alternative hypothesis: \\(H_A: \\mu \\ne 7.43~pounds\\). Create a filtered data frame called ncbirths_white that contain data only from white mothers. Then, calculate the mean of the weights of their babies. Are the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning. Lets discuss how this test would work. Our goal is to simulate a null distribution of sample means that is centered at the null value of 7.43 pounds. In order to do so, we take a bootstrap sample of from the original sample, calculate this bootstrap samples mean, repeat these two steps a large number of times to create a bootstrap distribution of means centered at the observed sample mean, shift this distribution to be centered at the null value by substracting / adding X to all boostrap mean (X = difference between mean of bootstrap distribution and null value), and calculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean. Run the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test. 5.7.2 Baby weight vs. smoking Consider the possible relationship between a mothers smoking habit and the weight of her baby. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions. Make side-by-side boxplots displaying the relationship between habit and weight. What does the plot highlight about the relationship between these two variables? Before moving forward, save a version of the dataset omitting observations where there are NAs for habit. You can call this version ncbirths_habitgiven. The box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the habit variable, and then calculate the mean weight in these groups using. ncbirths_habitgiven %&gt;% group_by(habit) %&gt;% summarise(mean_weight = mean(weight)) There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test . Write the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different. Are the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning. Run the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test. Construct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers. 5.7.3 Baby weight vs. mothers age In this portion of the analysis we focus on two variables. The first one is maturemom. First, a non-inference task: Determine the age cutoff for younger and mature mothers. Use a method of your choice, and explain how your method works. The other variable of interest is lowbirthweight. Conduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use \\(\\alpha = 0.05\\). If you find a significant difference, costruct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger moms, and interpret this interval in context of the data. 5.8 Lab 12 - Work on projects This week youll be working on your projects. Here are a few to do items to get you started. Once you complete these, use the rest of the time to, well, work on your project! Remind yourself of the project assignment Go to the course organization on GitHub and clone your project repo titled project-TEAM_NAME Add your project title and team name to the README.Rmd file in the repo and commit and push your changes. Observe that these are updated in the README of the repo. Open the presentation.Rmd file, knit the document, and review the presentation format. This is where your presentation will go. Update the YAML with your project title, team name, etc. and commit and push your changes. Go to your project repo on GitHub, click on Settings on the top right corner, and scroll down to the section titled GiHub Pages. Under Source, select master branch. This will give you a URL where the website for your project will be automatically built from the content in your README. This might take a few minutes. Click on the link to confirm that the website has been built. (Optional) Once the website it build, you can change its theme using the Theme Chooser. Also, once the website is built, youll need to pull changes to your project in RStudio. Take a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations. On your repo you should see a text on top No description, website, or topics provided.. Next to it theres an Edit button. Add a short description as well as the URL of your project website here. Note: This website is public, but your repository will remain private,unless you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work wont contain your score for the project. Add your dataset to the data folder and add your codebook to the README inthat folder. If in your proposal you were advised to update your codebook, make sure to make those updates. If you had R scripts you used to scrape your data, add them to this folder as well. Add the content from your proposal to the proposal.Rmd file in the proposal folder. Knit the document to make sure everything works and commit and push your proposal to your project repo. Important: Your data now lives in a folder called data that is not inside your proposal folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function. You dont need to make further updates to your proposal at this point, even if your plans for the project change slightly. Load your data in your presentation.Rmd, knit, and make sure everything works. Commit and push your updated proposal to your project repo. Important: Same note as above! Your data now lives in a folder called data that is not inside your presentation folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function. Now that all the logistical details are done, start working on your project. Open issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks. Strongly recommended: Get a hold of a tutor and run your ideas by them. "],["lab-13-collaborating-on-github.html", "Lab 6 Lab 13 - Collaborating on GitHub 6.1 GitHub issues 6.2 Project progress", " Lab 6 Lab 13 - Collaborating on GitHub This week youll continue working on your projects. The first half of the workshop is structured, and you can use the second half to make progress on your projects. 6.1 GitHub issues Issues are a great way to keep track of tasks, enhancements, and bugs for your projects. Theyre kind of like emailexcept they can be shared and discussed with the rest of your team. You can use issues as to-do lists as well as a place for brainstorming / discussing ideas. 6.1.1 Opening an issue Go to your project repo and open a new issue titled Practice issue. Add the following text to the issue: This is not a real issue. This is just some placeholder text. And the following is a bulleted to-do list: - [ ] Do this - [ ] Then that - [ ] And finally this Hit preview to make sure the issue looks like the following: Submit the issue. Then, assign the issue to one or few members of the team. 6.1.2 Working on the issue As you work on the issue you can check the boxes. Note that this will also show progress on the issue on the issue dashboard. Check some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard. 6.1.3 Closing the issue Once youre done with an issue, you should close it. You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue. Well practice the second one. If you preface your commits with Fixes, Fixed, Fix, Closes, Closed, or Close, the issue will be closed when you push the changes to your repo. Take a note of the issue number, which will show up next to the issue title. Go to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following: Add a new line to the README, closes #2 Push your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue. 6.2 Project progress Now back to your project Crafting your to-do list: Discuss your plan for your project as a team, and open at least n issues, where n is the number of students in your team. Not every issue needs to have a checklist, but you might want to include checklists in some of them to remind yourselves the exact steps you discussed to tackle the issue. Then assign at least one issue to each team member. Customizing your website theme: We attempted this last week, and failed due to permission issues. Lets try it one more time! Browse the possible GitHub themes demo pages at the following links. architect cayman dinky hacker leap-day merlot midnight minimal modernist slate tactile time machine Once you decide which theme you prefer (and its perfectly fine if its the default theme you had to begin with), go to the _config.yml file in your repo on RStudio and edit the theme name in the _config.yml file. For example, if you were going from cayman to hacker, your diff would look like the following. Once you commit and push this change, give it a couple minutes for the website to rebuild, and confirm that the theme was changed. **Note:** This is an extremely important step as this is the link I will use on the day of your presentation. There will not be time to make push updates once your presentation session starts. Updating your project description: If you have not yet done so, add a brief description, link to your project website, and topics to your project repo. Citing your data: Now is the time to fix up those citations! In your project README there is a link to a resource for properly citing data. Develop a citation for your dataset and add it under the data section using this guidance. If you have questions, ask a tutor for help! Confirming presentation format: Go to the website for your repo and click on the link that should take you to your presentation. Confirm that your latest changes to the presentation are reflected at this link (which means you must have pushed the resulting HTML file along with the Rmd file where you wrote your presentation). Confirming schedules: Go to the schedule for presentations and confirm that all team members can make it at the beginning of the hour youre assigned to present in. Also note that we will not be meeting in the computer lab. Some of you who have an ILA workshop before this class have been assigned to the first hour due to the sheer number of such students with conflicts. I have checked in with the ILA course organizer and have been told that next weeks workshop is revision, and the presentations in IDS should take priority. So please make sure to leave your workshop by 11:30 at the latest to get to Kings Buildings in time for the presentations. Order within each hour will be announced on the day of the presentations, so you should all be ready to go at the beginning of the hour. Tidying up your coding style: Go to the pull requests tab and take a look at the code styling suggestions. Implement them in the relevant files. Styling suggestions are generated daily at 13:30, so if you do more work today, there may be more suggestions tomorrow. Make sure to check these before you finalize work on your repo. Strongly recommended: Get a hold of a tutor and run your ideas by them. "],["references.html", "References", " References "]]
