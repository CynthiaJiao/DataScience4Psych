[["functions-part1.html", "30 Write your own R functions 30.1 What and why? 30.2 Load the Gapminder data 30.3 Example Analysis: Average Delay by Airline 30.4 Get something that works 30.5 Check the validity of arguments 30.6 Wrap-up and what’s next? 30.7 Where were we? Where are we going? 30.8 Load the Gapminder data 30.9 Restore our max minus min function 30.10 Generalize our function to other quantiles 30.11 Get something that works, again 30.12 Turn the working interactive code into a function, again 30.13 Argument names: freedom and conventions 30.14 What a function returns 30.15 Default values: freedom to NOT specify the arguments 30.16 Check the validity of arguments, again 30.17 Wrap-up and what’s next? 30.18 Where were we? Where are we going? 30.19 Load the Gapminder data 30.20 Restore our max minus min function 30.21 Be proactive about NAs 30.22 The useful but mysterious ... argument 30.23 Use testthat for formal unit tests", " 30 Write your own R functions Writing your own functions in R is a fundamental skill that enhances your ability to perform repetitive tasks efficiently, customize analyses, and improve the readability of your code. A function in R is a set of instructions designed to perform a specific task, which can be as simple or complex as needed. By now, you’ve used plenty of functions in R. Hopefully, you’ve absorbed some of their logic, and have seen first-hand how they simplify complex tasks. It’s time to take that experience and start crafting your own. Doing so isn’t just about following a set of instructions; it’s about embracing the modular, building-block nature of R. This approach doesn’t just make your code smarter; it makes it significantly more readable and customizable. Let’s dive in and transform how you interact with R, turning you from a useR into a creatoR. 30.1 What and why? This section aims to demystify the process experienced R useRs follow to write functions. I want to shed light on the rationale behind each step. Merely looking at the finished product, e.g., source code for R packages, can be extremely deceiving. Reality is generally much uglier … but more interesting! Why are we covering this now, smack in the middle of data aggregation? Powerful machines like dplyr, purrr, and the built-in “apply” family of functions, are ready and waiting to apply your purpose-built functions to various bits of your data. If you can express your analytical wishes in a function, these tools will give you great power. 30.2 Load the Gapminder data We’ll begin by loading the nycflights13 dataset, which contains information about all flights that departed from New York City in 2013. This dataset provides a rich source of real-world data for practicing data manipulation and analysis library(nycflights13) library(dplyr) data(&quot;flights&quot;) str(flights) #&gt; tibble [336,776 × 19] (S3: tbl_df/tbl/data.frame) #&gt; $ year : int [1:336776] 2013 2013 2013 2013 2013 2013 2013 2013 2013.. #&gt; $ month : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ day : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ dep_time : int [1:336776] 517 533 542 544 554 554 555 557 557 558 ... #&gt; $ sched_dep_time: int [1:336776] 515 529 540 545 600 558 600 600 600 600 ... #&gt; $ dep_delay : num [1:336776] 2 4 2 -1 -6 -4 -5 -3 -3 -2 ... #&gt; $ arr_time : int [1:336776] 830 850 923 1004 812 740 913 709 838 753 ... #&gt; $ sched_arr_time: int [1:336776] 819 830 850 1022 837 728 854 723 846 745 ... #&gt; $ arr_delay : num [1:336776] 11 20 33 -18 -25 12 19 -14 -8 8 ... #&gt; $ carrier : chr [1:336776] &quot;UA&quot; &quot;UA&quot; &quot;AA&quot; &quot;B6&quot; ... #&gt; $ flight : int [1:336776] 1545 1714 1141 725 461 1696 507 5708 79 301 .. #&gt; $ tailnum : chr [1:336776] &quot;N14228&quot; &quot;N24211&quot; &quot;N619AA&quot; &quot;N804JB&quot; ... #&gt; $ origin : chr [1:336776] &quot;EWR&quot; &quot;LGA&quot; &quot;JFK&quot; &quot;JFK&quot; ... #&gt; $ dest : chr [1:336776] &quot;IAH&quot; &quot;IAH&quot; &quot;MIA&quot; &quot;BQN&quot; ... #&gt; $ air_time : num [1:336776] 227 227 160 183 116 150 158 53 140 138 ... #&gt; $ distance : num [1:336776] 1400 1416 1089 1576 762 ... #&gt; $ hour : num [1:336776] 5 5 5 5 6 5 6 6 6 6 ... #&gt; $ minute : num [1:336776] 15 29 40 45 0 58 0 0 0 0 ... #&gt; $ time_hour : POSIXct[1:336776], format: &quot;2013-01-01 05:00:00&quot; &quot;2013-01-&quot;.. 30.3 Example Analysis: Average Delay by Airline Consider we want to compute the average delay experienced by each airline. This is a great example of a typical input for a function. You can imagine wanting to get this statistic to evaluate airline performance. You might want to do this for different years, months, or days of the week. You might want to do this for different airports, or for different combinations of airports. You might want to do this for different types of delays. You might want to do this for different subsets of the data, e.g., only for flights that were delayed. You might want to do this for different airlines. You might want to do this for different combinations of the above. 30.4 Get something that works First, develop some working code for interactive use, using a representative input. I’ll use flights operated by a specific airline as an example. R functions that will be useful: mean() and filter() from the dplyr package. ## Investigate the structure of the flights dataset str(flights) #&gt; tibble [336,776 × 19] (S3: tbl_df/tbl/data.frame) #&gt; $ year : int [1:336776] 2013 2013 2013 2013 2013 2013 2013 2013 2013.. #&gt; $ month : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ day : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ dep_time : int [1:336776] 517 533 542 544 554 554 555 557 557 558 ... #&gt; $ sched_dep_time: int [1:336776] 515 529 540 545 600 558 600 600 600 600 ... #&gt; $ dep_delay : num [1:336776] 2 4 2 -1 -6 -4 -5 -3 -3 -2 ... #&gt; $ arr_time : int [1:336776] 830 850 923 1004 812 740 913 709 838 753 ... #&gt; $ sched_arr_time: int [1:336776] 819 830 850 1022 837 728 854 723 846 745 ... #&gt; $ arr_delay : num [1:336776] 11 20 33 -18 -25 12 19 -14 -8 8 ... #&gt; $ carrier : chr [1:336776] &quot;UA&quot; &quot;UA&quot; &quot;AA&quot; &quot;B6&quot; ... #&gt; $ flight : int [1:336776] 1545 1714 1141 725 461 1696 507 5708 79 301 .. #&gt; $ tailnum : chr [1:336776] &quot;N14228&quot; &quot;N24211&quot; &quot;N619AA&quot; &quot;N804JB&quot; ... #&gt; $ origin : chr [1:336776] &quot;EWR&quot; &quot;LGA&quot; &quot;JFK&quot; &quot;JFK&quot; ... #&gt; $ dest : chr [1:336776] &quot;IAH&quot; &quot;IAH&quot; &quot;MIA&quot; &quot;BQN&quot; ... #&gt; $ air_time : num [1:336776] 227 227 160 183 116 150 158 53 140 138 ... #&gt; $ distance : num [1:336776] 1400 1416 1089 1576 762 ... #&gt; $ hour : num [1:336776] 5 5 5 5 6 5 6 6 6 6 ... #&gt; $ minute : num [1:336776] 15 29 40 45 0 58 0 0 0 0 ... #&gt; $ time_hour : POSIXct[1:336776], format: &quot;2013-01-01 05:00:00&quot; &quot;2013-01-&quot;.. ## get to know the functions mentioned above mean(flights$dep_delay) #&gt; [1] NA filter(.data = flights, carrier == &quot;AA&quot;) #&gt; # A tibble: 32,729 × 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 542 540 2 923 850 #&gt; 2 2013 1 1 558 600 -2 753 745 #&gt; 3 2013 1 1 559 600 -1 941 910 #&gt; 4 2013 1 1 606 610 -4 858 910 #&gt; 5 2013 1 1 623 610 13 920 915 #&gt; 6 2013 1 1 628 630 -2 1137 1140 #&gt; 7 2013 1 1 629 630 -1 824 810 #&gt; 8 2013 1 1 635 635 0 1028 940 #&gt; 9 2013 1 1 656 700 -4 854 850 #&gt; 10 2013 1 1 656 659 -3 949 959 #&gt; # ℹ 32,719 more rows #&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, #&gt; # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, #&gt; # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; library(dplyr) # Assuming flights is a dataframe with dep_delay and carrier columns flights %&gt;% na.omit() %&gt;% group_by(carrier) %&gt;% summarise(Mean_Dep_Delay = mean(dep_delay, na.rm = TRUE)) %&gt;% kable(col.names = c(&quot;Carrier&quot;, &quot;Average Departure Delay&quot;)) Carrier Average Departure Delay 9E 16.44 AA 8.57 AS 5.83 B6 12.97 DL 9.22 EV 19.84 F9 20.20 FL 18.61 HA 4.90 MQ 10.45 OO 12.59 UA 12.02 US 3.75 VX 12.76 WN 17.66 YV 18.90 Now lets go through some natureal solutions to get the average delay for the airline “AA” 30.4.1 Using dplyr for Data Filtering and Summary This solution employs the dplyr package to filter flights by the airline code and then calculate the average departure delay. flights %&gt;% filter(carrier == &quot;AA&quot;) %&gt;% summarise(average_delay = mean(dep_delay, na.rm = TRUE)) #&gt; # A tibble: 1 × 1 #&gt; average_delay #&gt; &lt;dbl&gt; #&gt; 1 8.59 30.4.2 Using Base R with Subsetting Here, we use base R to achieve the same task without the dplyr package, directly subsetting the dataframe. mean(flights$dep_delay[flights$carrier==&quot;AA&quot;], na.rm = TRUE) #&gt; [1] 8.59 30.4.3 Using with() Function The with() function provides a convenient way to perform operations within a dataframe subset, making the code more readable. with(flights[flights$carrier == &quot;AA&quot;, ], mean(dep_delay, na.rm = TRUE)) #&gt; [1] 8.59 30.4.4 Using aggregate() Function The aggregate() function in R can be used to compute summary statistics for subgroups of data, which in this case are flights operated by “AA”. aggregate(dep_delay ~ carrier, data = flights[flights$carrier == &quot;AA&quot;, ], FUN = mean, na.rm = TRUE)$dep_delay #&gt; [1] 8.59 30.4.5 Using tapply() Function The tapply() function applies a function to subsets of a vector, which we can use to calculate the average delay for “AA” flights. tapply(flights$dep_delay, flights$carrier, mean, na.rm = TRUE)[&quot;AA&quot;] #&gt; AA #&gt; 8.59 Now, internalize this “answer” because our informal testing relies on you noticing departures from this number when we generalize the function. 30.4.6 Turn the Working Interactive Code into a Function When crafting your own functions in R, it’s beneficial to start with a straightforward, minimal version that accomplishes the basic task at hand. This approach is akin to building a ‘skateboard’—a simple, yet functional product. Let’s apply this philosophy to our task of calculating the average delay for a specific airline in the nycflights13 dataset. Initial Simple Function: The ‘Skateboard’ average_delay_by_airline &lt;- function(airline_code) { flights %&gt;% filter(carrier == airline_code) %&gt;% summarise(average_delay = mean(dep_delay, na.rm = TRUE)) } Check that you’re getting the same answer as you did with your interactive code. # Test the function with American Airlines (AA) average_delay_by_airline(&quot;AA&quot;) #&gt; # A tibble: 1 × 1 #&gt; average_delay #&gt; &lt;dbl&gt; #&gt; 1 8.59 This function represents our ‘skateboard’. It’s basic, and we have added no new functionality. Yet, it gets the job done by providing the average delay for a given airline code. It doesn’t include error handling or support for additional details like distinguishing between departure and arrival delays, but it serves as a solid starting point. This is a minimal viable product (MVP) that we can build upon to create a more complex function (the ‘car’). Figure 30.1: This image [widely attributed to the Spotify development team][min-viable-product] conveys an important point. From Your ultimate guide to Minimum Viable Product (+great examples) This idea is related to the valuable [Telescope Rule][telescope-rule]: It is faster to make a four-inch mirror then a six-inch mirror than to make a six-inch mirror. 30.4.7 Test on new inputs Pick some new artificial inputs where you know (at least approximately) what your function should return. average_delay_by_airline(&quot;UA&quot;) #&gt; # A tibble: 1 × 1 #&gt; average_delay #&gt; &lt;dbl&gt; #&gt; 1 12.1 average_delay_by_airline(c(&quot;UA&quot;,&quot;AA&quot;)) #&gt; # A tibble: 1 × 1 #&gt; average_delay #&gt; &lt;dbl&gt; #&gt; 1 10.7 average_delay_by_airline(c(&quot;UA&quot;,&quot;AA&quot;)) #&gt; # A tibble: 1 × 1 #&gt; average_delay #&gt; &lt;dbl&gt; #&gt; 1 10.7 I know that 10 minus 1 is 9. I know that random uniform [0, 1] variates will be between 0 and 1. Therefore max - min should be less than 1. If I take LOTS of them, max - min should be pretty close to 1. It is intentional that I tested on integer input as well as floating point. Likewise, I like to use valid-but-random data for this sort of check. 30.4.8 Test on real data but different real data Back to the real world now. Two other quantitative variables are lying around: gdpPercap and pop. Let’s have a go. max_minus_min(gapminder$gdpPercap) #&gt; Error in max_minus_min(gapminder$gdpPercap): could not find function &quot;max_minus_min&quot; max_minus_min(gapminder$pop) #&gt; Error in max_minus_min(gapminder$pop): could not find function &quot;max_minus_min&quot; Either check these results “by hand” or apply the “does that even make sense?” test. 30.4.9 Test on unexpected stuff Now we try to break our function. Don’t get truly diabolical (yet). Just make the kind of mistakes you can imagine making at 2am when, 3 years from now, you rediscover this useful function you wrote. Give your function inputs it’s not expecting. max_minus_min(gapminder) ## hey sometimes things &quot;just work&quot; on data.frames! #&gt; Error in max_minus_min(gapminder): could not find function &quot;max_minus_min&quot; max_minus_min(gapminder$country) ## factors are kind of like integer vectors, no? #&gt; Error in max_minus_min(gapminder$country): could not find function &quot;max_minus_min&quot; max_minus_min(&quot;eggplants are purple&quot;) ## i have no excuse for this one #&gt; Error in max_minus_min(&quot;eggplants are purple&quot;): could not find function &quot;max_minus_min&quot; How happy are you with those error messages? You must imagine that some entire script has failed and that you were hoping to just source() it without re-reading it. If a colleague or future you encountered these errors, do you run screaming from the room? How hard is it to pinpoint the usage problem? 30.4.10 Unbreakable Here are some great examples where the function should break but it does not. max_minus_min(gapminder[c(&quot;lifeExp&quot;, &quot;gdpPercap&quot;, &quot;pop&quot;)]) #&gt; Error in max_minus_min(gapminder[c(&quot;lifeExp&quot;, &quot;gdpPercap&quot;, &quot;pop&quot;)]): could not find function &quot;max_minus_min&quot; max_minus_min(c(TRUE, TRUE, FALSE, TRUE, TRUE)) #&gt; Error in max_minus_min(c(TRUE, TRUE, FALSE, TRUE, TRUE)): could not find function &quot;max_minus_min&quot; In both cases, R’s eagerness to make sense of our requests is unfortunately successful. In the first case, a data.frame containing just the quantitative variables is eventually coerced into numeric vector. We can compute max minus min, even though it makes absolutely no sense at all. In the second case, a logical vector is converted to zeroes and ones, which might merit an error or at least a warning. 30.5 Check the validity of arguments For functions that will be used again – which is not all of them! – it is good to check the validity of arguments. This implements a rule from [the Unix philosophy][unix-philosophy]: Rule of Repair: When you must fail, fail noisily and as soon as possible. 30.5.1 stop if not stopifnot() is the entry level solution. I use it here to make sure the input x is a numeric vector. mmm &lt;- function(x) { stopifnot(is.numeric(x)) max(x) - min(x) } mmm(gapminder) #&gt; Error in eval(expr, envir, enclos): object &#39;gapminder&#39; not found mmm(gapminder$country) #&gt; Error in eval(expr, envir, enclos): object &#39;gapminder&#39; not found mmm(&quot;eggplants are purple&quot;) #&gt; Error in mmm(&quot;eggplants are purple&quot;): is.numeric(x) is not TRUE mmm(gapminder[c(&quot;lifeExp&quot;, &quot;gdpPercap&quot;, &quot;pop&quot;)]) #&gt; Error in eval(expr, envir, enclos): object &#39;gapminder&#39; not found mmm(c(TRUE, TRUE, FALSE, TRUE, TRUE)) #&gt; Error in mmm(c(TRUE, TRUE, FALSE, TRUE, TRUE)): is.numeric(x) is not TRUE And we see that it catches all of the self-inflicted damage we would like to avoid. 30.5.2 if then stop stopifnot() doesn’t provide a helpful error message. The next approach is widely used. Put your validity check inside an if() statement and call stop() yourself, with a custom error message, in the body. mmm2 &lt;- function(x) { if (!is.numeric(x)) { stop( &quot;I am so sorry, but this function only works for numeric input!\\n&quot;, &quot;You have provided an object of class: &quot;, class(x)[1] ) } max(x) - min(x) } mmm2(gapminder) #&gt; Error in eval(expr, envir, enclos): object &#39;gapminder&#39; not found In addition to a gratuitous apology, the error raised also contains two more pieces of helpful info: Which function threw the error. Hints on how to fix things: expected class of input vs actual class. If it is easy to do so, I highly recommend this template: “you gave me THIS, but I need THAT”. The tidyverse style guide has a very useful chapter on how to construct error messages. 30.5.3 Sidebar: non-programming uses for assertions Another good use of this pattern is to leave checks behind in data analytical scripts. Consider our repetitive use of Gapminder in this course. Every time we load it, we inspect it, hoping to see the usual stuff. If we were loading from file (vs. a stable data package), we might want to formalize our expectations about the number of rows and columns, the names and flavors of the variables, etc. This would alert us if the data suddenly changed, which can be a useful wake-up call in scripts that you re-run ad nauseam on auto-pilot or non-interactively. 30.6 Wrap-up and what’s next? Here’s the function we’ve written so far: mmm2 #&gt; function(x) { #&gt; if (!is.numeric(x)) { #&gt; stop( #&gt; &quot;I am so sorry, but this function only works for numeric input!\\n&quot;, #&gt; &quot;You have provided an object of class: &quot;, class(x)[1] #&gt; ) #&gt; } #&gt; max(x) - min(x) #&gt; } What we’ve accomplished: We’ve written our first function. We are checking the validity of its input, argument x. We’ve done a good amount of informal testing. Where to next? In part 2 we generalize this function to take differences in other quantiles and learn how to set default values for arguments. 30.7 Where were we? Where are we going? In part 1 we wrote our simple R function to compute the difference between the max and min of a numeric vector. We checked the validity of the function’s only argument and, informally, we verified that it worked pretty well. In this part, we generalize this function, learn more technical details about R functions, and set default values for some arguments. 30.8 Load the Gapminder data As usual, load gapminder. library(gapminder) 30.9 Restore our max minus min function Let’s keep our previous function around as a baseline. mmm &lt;- function(x) { stopifnot(is.numeric(x)) max(x) - min(x) } 30.10 Generalize our function to other quantiles The max and the min are special cases of a quantile. Here are other special cases you may have heard of: median = 0.5 quantile 1st quartile = 0.25 quantile 3rd quartile = 0.75 quantile If you’re familiar with [box plots][wiki-boxplot], the rectangle typically runs from the 1st quartile to the 3rd quartile, with a line at the median. If \\(q\\) is the \\(p\\)-th quantile of a set of \\(n\\) observations, what does that mean? Approximately \\(pn\\) of the observations are less than \\(q\\) and \\((1 - p)n\\) are greater than \\(q\\). Yeah, you need to worry about rounding to an integer and less/greater than or equal to, but these details aren’t critical here. Let’s generalize our function to take the difference between any two quantiles. We can still consider the max and min, if we like, but we’re not limited to that. 30.11 Get something that works, again The eventual inputs to our new function will be the data x and two probabilities. First, play around with the quantile() function. Convince yourself you know how to use it, for example, by cross-checking your results with other built-in functions. quantile(gapminder$lifeExp) #&gt; 0% 25% 50% 75% 100% #&gt; 23.6 48.2 60.7 70.8 82.6 quantile(gapminder$lifeExp, probs = 0.5 ) #&gt; 50% #&gt; 60.7 median(gapminder$lifeExp) #&gt; [1] 60.7 quantile(gapminder$lifeExp, robs = c(0.25, 0.75) ) #&gt; 0% 25% 50% 75% 100% #&gt; 23.6 48.2 60.7 70.8 82.6 boxplot(gapminder$lifeExp, plot = FALSE)$stats #&gt; [,1] #&gt; [1,] 23.6 #&gt; [2,] 48.2 #&gt; [3,] 60.7 #&gt; [4,] 70.8 #&gt; [5,] 82.6 Now write a code snippet that takes the difference between two quantiles. the_probs &lt;- c(0.25, 0.75) the_quantiles &lt;- quantile(gapminder$lifeExp, probs = the_probs) max(the_quantiles) - min(the_quantiles) #&gt; [1] 22.6 30.12 Turn the working interactive code into a function, again I’ll use qdiff as the base of our function’s name. I copy the overall structure from our previous “max minus min” work but replace the guts of the function with the more general code we just developed. qdiff1 &lt;- function(x, probs) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x = x, probs = probs) max(the_quantiles) - min(the_quantiles) } qdiff1(gapminder$lifeExp, probs = c(0.25, 0.75)) #&gt; [1] 22.6 IQR(gapminder$lifeExp) # hey, we&#39;ve reinvented IQR #&gt; [1] 22.6 qdiff1(gapminder$lifeExp, probs = c(0, 1)) #&gt; [1] 59 mmm(gapminder$lifeExp) #&gt; [1] 59 Again we do some informal tests against familiar results and external implementations. 30.13 Argument names: freedom and conventions I want you to understand the importance of argument names. I can name my arguments almost anything I like. Proof: qdiff2 &lt;- function(zeus, hera) { stopifnot(is.numeric(zeus)) the_quantiles &lt;- quantile(x = zeus, probs = hera) max(the_quantiles) - min(the_quantiles) } qdiff2(zeus = gapminder$lifeExp, hera = 0:1) #&gt; [1] 59 Although I can name my arguments after Greek gods, it’s usually a bad idea. Take all opportunities to make things more self-explanatory via meaningful names. Future you will thank you. If you are going to pass the arguments of your function as arguments of a built-in function, consider copying the argument names. Unless you have a good reason to do your own thing (some argument names are bad!), be consistent with the existing function. Again, the reason is to reduce your cognitive load. This is what I’ve been doing all along and now you know why: qdiff1 #&gt; function(x, probs) { #&gt; stopifnot(is.numeric(x)) #&gt; the_quantiles &lt;- quantile(x = x, probs = probs) #&gt; max(the_quantiles) - min(the_quantiles) #&gt; } #&gt; &lt;bytecode: 0x00000160ae85af98&gt; We took this detour so you could see there is no structural relationship between my arguments (x and probs) and those of quantile() (also x and probs). The similarity or equivalence of the names accomplishes nothing as far as R is concerned; it is solely for the benefit of humans reading, writing, and using the code. Which is very important! 30.14 What a function returns By this point, I expect someone will have asked about the last line in my function’s body. Look above for a reminder of the function’s definition. By default, a function returns the result of the last line of the body. I am just letting that happen with the line max(the_quantiles) - min(the_quantiles). However, there is an explicit function for this: return(). I could just as easily make this the last line of my function’s body: return(max(the_quantiles) - min(the_quantiles)) You absolutely must use return() if you want to return early based on some condition, i.e. before execution gets to the last line of the body. Otherwise, you can decide your own conventions about when you use return() and when you don’t. 30.15 Default values: freedom to NOT specify the arguments What happens if we call our function but neglect to specify the probabilities? qdiff1(gapminder$lifeExp) #&gt; Error in qdiff1(gapminder$lifeExp): argument &quot;probs&quot; is missing, with no default Oops! At the moment, this causes a fatal error. It can be nice to provide some reasonable default values for certain arguments. In our case, it would not be a good idea to specify a default value for the primary input x, but it would be a good idea to specify a default for probs. We started by focusing on the max and the min, so I think those make reasonable defaults. Here’s how to specify that in a function definition. qdiff3 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs) max(the_quantiles) - min(the_quantiles) } Again we check how the function works, in old examples and new, specifying the probs argument and not. qdiff3(gapminder$lifeExp) #&gt; [1] 59 mmm(gapminder$lifeExp) #&gt; [1] 59 qdiff3(gapminder$lifeExp, c(0.1, 0.9)) #&gt; [1] 33.6 30.16 Check the validity of arguments, again Exercise: upgrade our argument validity checks in light of the new argument probs. ## problems identified during class ## we&#39;re not checking that probs is numeric ## we&#39;re not checking that probs is length 2 ## we&#39;re not checking that probs are in [0,1] 30.17 Wrap-up and what’s next? Here’s the function we’ve written so far: qdiff3 #&gt; function(x, probs = c(0, 1)) { #&gt; stopifnot(is.numeric(x)) #&gt; the_quantiles &lt;- quantile(x, probs) #&gt; max(the_quantiles) - min(the_quantiles) #&gt; } #&gt; &lt;bytecode: 0x00000160af986cc8&gt; What we’ve accomplished: We’ve generalized our first function to take a difference between arbitrary quantiles. We’ve specified default values for the probabilities that set the quantiles. Where to next? Next, we tackle NAs, the special ... argument, and formal unit testing. 30.18 Where were we? Where are we going? Previously, we generalized our first R function so it could take the difference between any two quantiles of a numeric vector. We also set default values for the underlying probabilities, so that, by default, we compute the max minus the min. In this part, we tackle NAs, the special argument ... and formal testing. 30.19 Load the Gapminder data As usual, load gapminder. library(gapminder) 30.20 Restore our max minus min function Let’s keep our previous function around as a baseline. qdiff3 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs) max(the_quantiles) - min(the_quantiles) } 30.21 Be proactive about NAs I am being gentle by letting you practice with the Gapminder data. In real life, missing data will make your life a living hell. If you are lucky, it will be properly indicated by the special value NA, but don’t hold your breath. Many built-in R functions have an na.rm = argument through which you can specify how you want to handle NAs. Typically the default value is na.rm = FALSE and typical default behavior is to either let NAs propagate or to raise an error. Let’s see how quantile() handles NAs: z &lt;- gapminder$lifeExp z[3] &lt;- NA quantile(gapminder$lifeExp) #&gt; 0% 25% 50% 75% 100% #&gt; 23.6 48.2 60.7 70.8 82.6 quantile(z) #&gt; Error in quantile.default(z): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE quantile(z, na.rm = TRUE) #&gt; 0% 25% 50% 75% 100% #&gt; 23.6 48.2 60.8 70.8 82.6 So quantile() simply will not operate in the presence of NAs unless na.rm = TRUE. How shall we modify our function? If we wanted to hardwire na.rm = TRUE, we could. Focus on our call to quantile() inside our function definition. qdiff4 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs, na.rm = TRUE) max(the_quantiles) - min(the_quantiles) } qdiff4(gapminder$lifeExp) #&gt; [1] 59 qdiff4(z) #&gt; [1] 59 This works but it is dangerous to invert the default behavior of a well-known built-in function and to provide the user with no way to override this. We could add an na.rm = argument to our own function. We might even enforce our preferred default – but at least we’re giving the user a way to control the behavior around NAs. qdiff5 &lt;- function(x, probs = c(0, 1), na.rm = TRUE) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs, na.rm = na.rm) max(the_quantiles) - min(the_quantiles) } qdiff5(gapminder$lifeExp) #&gt; [1] 59 qdiff5(z) #&gt; [1] 59 qdiff5(z, na.rm = FALSE) #&gt; Error in quantile.default(x, probs, na.rm = na.rm): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE 30.22 The useful but mysterious ... argument You probably could have lived a long and happy life without knowing there are at least 9 different algorithms for computing quantiles. [Go read about the type argument][rdocs-quantile] of quantile(). TLDR: If a quantile is not unambiguously equal to an observed data point, you must somehow average two data points. You can weight this average different ways, depending on the rest of the data, and type = controls this. Let’s say we want to give the user of our function the ability to specify how the quantiles are computed, but we want to accomplish with as little fuss as possible. In fact, we don’t even want to clutter our function’s interface with this! This calls for the very special ... argument. In English, this set of three dots is frequently called an “ellipsis”. qdiff6 &lt;- function(x, probs = c(0, 1), na.rm = TRUE, ...) { the_quantiles &lt;- quantile(x = x, probs = probs, na.rm = na.rm, ...) max(the_quantiles) - min(the_quantiles) } The practical significance of the type = argument is virtually nonexistent, so we can’t demo with the Gapminder data. Thanks to [@wrathematics][twitter-wrathematics], here’s a small example where we can (barely) detect a difference due to type. set.seed(1234) z &lt;- rnorm(10) quantile(z, type = 1) #&gt; 0% 25% 50% 75% 100% #&gt; -2.346 -0.890 -0.564 0.429 1.084 quantile(z, type = 4) #&gt; 0% 25% 50% 75% 100% #&gt; -2.346 -1.049 -0.564 0.353 1.084 all.equal(quantile(z, type = 1), quantile(z, type = 4)) #&gt; [1] &quot;Mean relative difference: 0.178&quot; Now we can call our function, requesting that quantiles be computed in different ways. qdiff6(z, probs = c(0.25, 0.75), type = 1) #&gt; [1] 1.32 qdiff6(z, probs = c(0.25, 0.75), type = 4) #&gt; [1] 1.4 While the difference may be subtle, it’s there. Marvel at the fact that we have passed type = 1 through to quantile() even though it was not a formal argument of our own function. The special argument ... is very useful when you want the ability to pass arbitrary arguments down to another function, but without constantly expanding the formal arguments to your function. This leaves you with a less cluttered function definition and gives you future flexibility to specify these arguments only when you need to. You will also encounter the ... argument in many built-in functions – read up on [c()][rdocs-c] or [list()][rdocs-list] – and now you have a better sense of what it means. It is not a breezy “and so on and so forth.” There are also downsides to ..., so use it with intention. In a package, you will have to work harder to create truly informative documentation for your user. Also, the quiet, absorbent properties of ... mean it can sometimes silently swallow other named arguments, when the user has a typo in the name. Depending on whether or how this fails, it can be a little tricky to find out what went wrong. The ellipsis package provides tools that help package developers use ... more safely. The in-progress tidyverse principles guide provides further guidance on the design of functions that take ... in Data, dots, details. 30.23 Use testthat for formal unit tests Until now, we’ve relied on informal tests of our evolving function. If you are going to use a function a lot, especially if it is part of a package, it is wise to use formal unit tests. The [testthat][testthat-web] package ([cran][testthat-cran]; [GitHub][testthat-github]) provides excellent facilities for this, with a distinct emphasis on automated unit testing of entire packages. However, we can take it out for a test drive even with our one measly function. We will construct a test with test_that() and, within it, we put one or more expectations that check actual against expected results. You simply harden your informal, interactive tests into formal unit tests. Here are some examples of tests and indicative expectations. library(testthat) test_that(&quot;invalid args are detected&quot;, { expect_error(qdiff6(&quot;eggplants are purple&quot;)) expect_error(qdiff6(iris)) }) test_that(&quot;NA handling works&quot;, { expect_error(qdiff6(c(1:5, NA), na.rm = FALSE)) expect_equal(qdiff6(c(1:5, NA)), 4) }) No news is good news! Let’s see what test failure would look like. Let’s revert to a version of our function that does no NA handling, then test for proper NA handling. We can watch it fail. qdiff_no_NA &lt;- function(x, probs = c(0, 1)) { the_quantiles &lt;- quantile(x = x, probs = probs) max(the_quantiles) - min(the_quantiles) } test_that(&quot;NA handling works&quot;, { expect_that(qdiff_no_NA(c(1:5, NA)), equals(4)) }) Similar to the advice to use assertions in data analytical scripts, I recommend you use unit tests to monitor the behavior of functions you (or others) will use often. If your tests cover the function’s important behavior, then you can edit the internals freely. You’ll rest easy in the knowledge that, if you broke anything important, the tests will fail and alert you to the problem. A function that is important enough for unit tests probably also belongs in a package, where there are obvious mechanisms for running the tests as part of overall package checks. "],["functions-practicum.html", "31 Function-writing practicum 31.1 Overview 31.2 Load the Gapminder data 31.3 Get data to practice with 31.4 Get some code that works 31.5 Turn working code into a function 31.6 Test on other data and in a clean workspace 31.7 Are we there yet? 31.8 Resources", " 31 Function-writing practicum 31.1 Overview We recently learned how to write our own R functions (part 1, part 2, part 3). Now we use that knowledge to write another useful function, within the context of the Gapminder data: Input: a data.frame that contains (at least) a life expectancy variable lifeExp and a variable for year year Output: a vector of estimated intercept and slope, from a linear regression of lifeExp on year The ultimate goal is to apply this function to the Gapminder data for a specific country. We will eventually scale up to all countries using external machinery, e.g., the dplyr::group_by() + dplyr::do(). 31.2 Load the Gapminder data As usual, load gapminder. Load ggplot2 because we’ll make some plots and load dplyr too. library(gapminder) library(ggplot2) library(dplyr) 31.3 Get data to practice with I extract the data for one country in order to develop some working code interactively. j_country &lt;- &quot;France&quot; # pick, but do not hard wire, an example (j_dat &lt;- gapminder %&gt;% filter(country == j_country)) #&gt; # A tibble: 12 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 France Europe 1952 67.4 42459667 7030. #&gt; 2 France Europe 1957 68.9 44310863 8663. #&gt; 3 France Europe 1962 70.5 47124000 10560. #&gt; 4 France Europe 1967 71.6 49569000 13000. #&gt; 5 France Europe 1972 72.4 51732000 16107. #&gt; 6 France Europe 1977 73.8 53165019 18293. #&gt; 7 France Europe 1982 74.9 54433565 20294. #&gt; 8 France Europe 1987 76.3 55630100 22066. #&gt; 9 France Europe 1992 77.5 57374179 24704. #&gt; 10 France Europe 1997 78.6 58623428 25890. #&gt; 11 France Europe 2002 79.6 59925035 28926. #&gt; 12 France Europe 2007 80.7 61083916 30470. Always always always plot the data. Yes, even now. p &lt;- ggplot(j_dat, aes(x = year, y = lifeExp)) p + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) #&gt; `geom_smooth()` using formula = &#39;y ~ x&#39; 31.4 Get some code that works Fit the regression: j_fit &lt;- lm(lifeExp ~ year, j_dat) coef(j_fit) #&gt; (Intercept) year #&gt; -397.765 0.239 Whoa, check out that wild intercept! Apparently the life expectancy in France around year 0 A.D. was minus 400 years! Never forget to sanity check a model. In this case, a reparametrization is in order. I think it makes more sense for the intercept to correspond to life expectancy in 1952, the earliest date in our dataset. Estimate the intercept eye-ball-o-metrically from the plot and confirm that we’ve got something sane and interpretable now. j_fit &lt;- lm(lifeExp ~ I(year - 1952), j_dat) coef(j_fit) #&gt; (Intercept) I(year - 1952) #&gt; 67.790 0.239 31.4.1 Sidebar: regression stuff There are two things above that might prompt questions. First, how did I know to get the estimated coefficients from a fitted model via coef()? Years of experience. But how might a novice learn such things? Read [the documentation for lm()][rdocs-lm], in this case. The “See also” section advises us about many functions that can operate on fitted linear model objects, including, but by no means limited to, coef(). Read [the documentation on coef()][rdocs-coef] too. Second, what am I doing here: lm(lifeExp ~ I(year - 1952))? I want the intercept to correspond to 1952 and an easy way to accomplish that is to create a new predictor on the fly: year minus 1952. The way I achieve that in the model formula, I(year - 1952), uses the I() function which “inhibits interpretation/conversion of objects”. By protecting the expression year - 1952, I ensure it is interpreted in the obvious arithmetical way. 31.5 Turn working code into a function Create the basic definition of a function and drop your working code inside. Add arguments and edit the inner code to match. Apply it to the practice data. Do you get the same result as before? le_lin_fit &lt;- function(dat, offset = 1952) { the_fit &lt;- lm(lifeExp ~ I(year - offset), dat) coef(the_fit) } le_lin_fit(j_dat) #&gt; (Intercept) I(year - offset) #&gt; 67.790 0.239 I had to decide how to handle the offset. Given that I will scale this code up to many countries, which, in theory, might have data for different dates, I chose to set a default of 1952. Strategies that compute the offset from data, either the main Gapminder dataset or the excerpt passed to this function, are also reasonable to consider. I loathe the names on this return value. This is not my first rodeo and I know that, downstream, these will contaminate variable names and factor levels and show up in public places like plots and tables. Fix names early! le_lin_fit &lt;- function(dat, offset = 1952) { the_fit &lt;- lm(lifeExp ~ I(year - offset), dat) setNames(coef(the_fit), c(&quot;intercept&quot;, &quot;slope&quot;)) } le_lin_fit(j_dat) #&gt; intercept slope #&gt; 67.790 0.239 Much better! 31.6 Test on other data and in a clean workspace It’s always good to rotate through examples during development. The most common error this will help you catch is when you accidentally hard-wire your example into your function. If you’re paying attention to your informal tests, you will find it creepy that your function returns exactly the same results regardless which input data you give it. This actually happened to me while I was writing this document, I kid you not! I had left j_fit inside the call to coef(), instead of switching it to the_fit. How did I catch that error? I saw the fitted line below, which clearly did not have an intercept in the late 60s and a positive slope, as my first example did. Figures are a mighty weapon in the fight against nonsense. I don’t trust analyses that have few/no figures. j_country &lt;- &quot;Zimbabwe&quot; (j_dat &lt;- gapminder %&gt;% filter(country == j_country)) #&gt; # A tibble: 12 × 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zimbabwe Africa 1952 48.5 3080907 407. #&gt; 2 Zimbabwe Africa 1957 50.5 3646340 519. #&gt; 3 Zimbabwe Africa 1962 52.4 4277736 527. #&gt; 4 Zimbabwe Africa 1967 54.0 4995432 570. #&gt; 5 Zimbabwe Africa 1972 55.6 5861135 799. #&gt; 6 Zimbabwe Africa 1977 57.7 6642107 686. #&gt; 7 Zimbabwe Africa 1982 60.4 7636524 789. #&gt; 8 Zimbabwe Africa 1987 62.4 9216418 706. #&gt; 9 Zimbabwe Africa 1992 60.4 10704340 693. #&gt; 10 Zimbabwe Africa 1997 46.8 11404948 792. #&gt; 11 Zimbabwe Africa 2002 40.0 11926563 672. #&gt; 12 Zimbabwe Africa 2007 43.5 12311143 470. p &lt;- ggplot(j_dat, aes(x = year, y = lifeExp)) p + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) #&gt; `geom_smooth()` using formula = &#39;y ~ x&#39; le_lin_fit(j_dat) #&gt; intercept slope #&gt; 55.221 -0.093 The linear fit is comically bad, but yes I believe the visual line and the regression results match up. It’s also a good idea to clean out the workspace, rerun the minimum amount of code, and retest your function. This will help you catch another common mistake: accidentally relying on objects that were lying around in the workspace during development but that are not actually defined in your function nor passed as formal arguments. rm(list = ls()) le_lin_fit &lt;- function(dat, offset = 1952) { the_fit &lt;- lm(lifeExp ~ I(year - offset), dat) setNames(coef(the_fit), c(&quot;intercept&quot;, &quot;slope&quot;)) } le_lin_fit(gapminder %&gt;% filter(country == &quot;Zimbabwe&quot;)) #&gt; intercept slope #&gt; 55.221 -0.093 31.7 Are we there yet? Yes. Given how I plan to use this function, I don’t feel the need to put it under formal unit tests or put in argument validity checks. 31.8 Resources Packages for runtime assertions (the last 3 seem to be under more active development than assertthat): assertthat on [cran][assertthat-cran] and [GitHub][assertthat-github] - the Hadleyverse option ensurer on [cran][ensurer-cran] and [GitHub][ensurer-github] - general purpose, pipe-friendly assertr on [cran][assertr-cran] and [GitHub][assertr-github] - explicitly data pipeline oriented assertive on [cran][assertive-cran] and [Bitbucket][assertive-bitbucket] - rich set of built-in functions Hadley Wickham’s book Advanced R (2015): Section on [defensive programming][adv-r-defensive-programming] Section on [function arguments][adv-r-fxn-args] Section on [return values][adv-r-return-values] Unit testing with testthat On [cran][testthat-cran], development on [GitHub][testthat-github], main [webpage][testthat-web] Wickham and Bryan’s [R Packages][r-pkgs2] book (in progress) Testing chapter Wickham’s testthat: Get Started with Testing article in The R Journal (2011). Maybe this is completely superseded by the newer chapter above? Be aware that parts could be out of date, but I recall it was a helpful read. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
